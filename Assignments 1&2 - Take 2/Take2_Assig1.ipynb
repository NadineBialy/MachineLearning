{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Exercise 1: Linear Regression\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you will implement linear regression and get to see it work on data. We will be using [`numpy`](http://www.numpy.org/) for all arrays and matrix operations, and [`matplotlib`](https://matplotlib.org/) for plotting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Semester 10\\\\Machine Learning\\\\Take2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for manipulating directory paths\n",
    "import os\n",
    "\n",
    "# Scientific and vector computation for python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "# Plotting library\n",
    "from matplotlib import pyplot\n",
    "from mpl_toolkits.mplot3d import Axes3D  # needed to plot 3-D surfaces\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "If you have successfully completed the material above, congratulations! You now understand linear regression and should able to start using it on your own datasets.\n",
    "\n",
    "For the rest of this programming exercise, we have included the following optional exercises. These exercises will help you gain a deeper understanding of the material, and if you are able to do so, we encourage you to complete them as well. You can still submit your solutions to these exercises to check if your answers are correct.\n",
    "\n",
    "## 3 Linear regression with multiple variables\n",
    "\n",
    "In this part, you will implement linear regression with multiple variables to predict the prices of houses. Suppose you are selling your house and you want to know what a good market price would be. One way to do this is to first collect information on recent houses sold and make a model of housing prices.\n",
    "\n",
    "The file `Data/ex1data2.txt` contains a training set of housing prices in Portland, Oregon. The first column is the size of the house (in square feet), the second column is the number of bedrooms, and the third column is the price\n",
    "of the house. \n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "### 3.1 Feature Normalization\n",
    "\n",
    "We start by loading and displaying some values from this dataset. By looking at the values, note that house sizes are about 1000 times the number of bedrooms. When features differ by orders of magnitude, first performing feature scaling can make gradient descent converge much more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17999, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(r'C:\\Users\\Lenovo\\Desktop\\Semester 10\\Machine Learning\\Take2\\house_prices_data_training_data.csv')\n",
    "\n",
    "data.drop(['id'], axis=1,inplace=True)\n",
    "data.drop(['date'], axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#independant feature x\n",
    "#x = data[['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view','condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated','zipcode','lat','long','sqft_living15','sqft_lot15']]\n",
    "#dependant feature y\n",
    "#y = data['price']\n",
    "\n",
    "data.head()\n",
    "data.shape\n",
    "\n",
    "#this x and y will later be splitted into train and test and then we are going to train our model based on our train data and i'll be able to test test the accuracy based on our test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
    "#x_train.shape, y_train.shape\n",
    "#x_test.shape, y_test.shape\n",
    "\n",
    "train, validate, test = np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])\n",
    "\n",
    "\n",
    "#knnclassifier = KNeighborsClassifier(n_neighbors=5)\n",
    "#knnclassifier.fit(x_train,y_train)\n",
    "#y_pred = knnclassifier.predict(x_test)\n",
    "#metrics.accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>695000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1140</td>\n",
       "      <td>3990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1140</td>\n",
       "      <td>0</td>\n",
       "      <td>1924</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6554</td>\n",
       "      <td>-122.333</td>\n",
       "      <td>1800</td>\n",
       "      <td>5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>345000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1990</td>\n",
       "      <td>20466</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1410</td>\n",
       "      <td>580</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98010</td>\n",
       "      <td>47.3259</td>\n",
       "      <td>-121.896</td>\n",
       "      <td>1660</td>\n",
       "      <td>93393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11248</th>\n",
       "      <td>575000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1630</td>\n",
       "      <td>5750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1160</td>\n",
       "      <td>470</td>\n",
       "      <td>1947</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>47.5674</td>\n",
       "      <td>-122.384</td>\n",
       "      <td>1640</td>\n",
       "      <td>5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15516</th>\n",
       "      <td>724000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1560</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1560</td>\n",
       "      <td>0</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.7006</td>\n",
       "      <td>-122.386</td>\n",
       "      <td>2620</td>\n",
       "      <td>5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14431</th>\n",
       "      <td>735000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2250</td>\n",
       "      <td>11520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7619</td>\n",
       "      <td>-122.268</td>\n",
       "      <td>2730</td>\n",
       "      <td>12445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "2581   695000.0         2       1.00         1140      3990     1.0   \n",
       "5391   345000.0         3       2.50         1990     20466     1.5   \n",
       "11248  575000.0         4       1.75         1630      5750     1.0   \n",
       "15516  724000.0         2       1.00         1560      5000     1.5   \n",
       "14431  735000.0         3       1.75         2250     11520     1.0   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "2581            0     0          3      7        1140              0   \n",
       "5391            0     0          4      8        1410            580   \n",
       "11248           0     0          3      7        1160            470   \n",
       "15516           0     1          4      7        1560              0   \n",
       "14431           0     1          3      8        2250              0   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "2581       1924             0    98103  47.6554 -122.333           1800   \n",
       "5391       1987             0    98010  47.3259 -121.896           1660   \n",
       "11248      1947             0    98116  47.5674 -122.384           1640   \n",
       "15516      1942             0    98117  47.7006 -122.386           2620   \n",
       "14431      1956             0    98028  47.7619 -122.268           2730   \n",
       "\n",
       "       sqft_lot15  \n",
       "2581         5700  \n",
       "5391        93393  \n",
       "11248        5750  \n",
       "15516        5400  \n",
       "14431       12445  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9965</th>\n",
       "      <td>485000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2900</td>\n",
       "      <td>35273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2900</td>\n",
       "      <td>0</td>\n",
       "      <td>1986</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.4013</td>\n",
       "      <td>-122.030</td>\n",
       "      <td>2510</td>\n",
       "      <td>38487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>537000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1400</td>\n",
       "      <td>4800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1200</td>\n",
       "      <td>200</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6865</td>\n",
       "      <td>-122.379</td>\n",
       "      <td>1440</td>\n",
       "      <td>3840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>355000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1420</td>\n",
       "      <td>3060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>860</td>\n",
       "      <td>560</td>\n",
       "      <td>1923</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6872</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1350</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>617000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>3020</td>\n",
       "      <td>360241</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3020</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0</td>\n",
       "      <td>98092</td>\n",
       "      <td>47.2662</td>\n",
       "      <td>-122.088</td>\n",
       "      <td>1890</td>\n",
       "      <td>209959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>615000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2120</td>\n",
       "      <td>3720</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2120</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98029</td>\n",
       "      <td>47.5526</td>\n",
       "      <td>-121.994</td>\n",
       "      <td>2170</td>\n",
       "      <td>3720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>439000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>790</td>\n",
       "      <td>2400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>790</td>\n",
       "      <td>0</td>\n",
       "      <td>1918</td>\n",
       "      <td>0</td>\n",
       "      <td>98122</td>\n",
       "      <td>47.6178</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1580</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15432</th>\n",
       "      <td>660000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2290</td>\n",
       "      <td>9120</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2290</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5613</td>\n",
       "      <td>-122.128</td>\n",
       "      <td>2290</td>\n",
       "      <td>9120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10924</th>\n",
       "      <td>305000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2210</td>\n",
       "      <td>9371</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2210</td>\n",
       "      <td>0</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>98032</td>\n",
       "      <td>47.3634</td>\n",
       "      <td>-122.279</td>\n",
       "      <td>2300</td>\n",
       "      <td>11584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>302000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>900</td>\n",
       "      <td>423838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>1925</td>\n",
       "      <td>0</td>\n",
       "      <td>98022</td>\n",
       "      <td>47.2280</td>\n",
       "      <td>-122.088</td>\n",
       "      <td>1810</td>\n",
       "      <td>94960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14516</th>\n",
       "      <td>230000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1710</td>\n",
       "      <td>5200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1030</td>\n",
       "      <td>680</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3651</td>\n",
       "      <td>-122.094</td>\n",
       "      <td>1390</td>\n",
       "      <td>5200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "9965   485000.0         3       2.25         2900     35273     2.0   \n",
       "2532   537000.0         3       2.50         1400      4800     1.0   \n",
       "11381  355000.0         3       0.75         1420      3060     1.0   \n",
       "1703   617000.0         3       1.75         3020    360241     2.0   \n",
       "11649  615000.0         4       2.50         2120      3720     2.0   \n",
       "...         ...       ...        ...          ...       ...     ...   \n",
       "3253   439000.0         1       1.00          790      2400     1.0   \n",
       "15432  660000.0         4       2.50         2290      9120     2.0   \n",
       "10924  305000.0         4       2.25         2210      9371     2.0   \n",
       "2871   302000.0         2       1.00          900    423838     1.0   \n",
       "14516  230000.0         3       2.00         1710      5200     1.0   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "9965            0     0          3      9        2900              0   \n",
       "2532            0     0          3      7        1200            200   \n",
       "11381           0     0          4      7         860            560   \n",
       "1703            0     0          3      8        3020              0   \n",
       "11649           0     0          3      8        2120              0   \n",
       "...           ...   ...        ...    ...         ...            ...   \n",
       "3253            0     0          3      7         790              0   \n",
       "15432           0     0          4      8        2290              0   \n",
       "10924           0     0          4      8        2210              0   \n",
       "2871            0     2          5      6         900              0   \n",
       "14516           0     0          5      7        1030            680   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "9965       1986             0    98038  47.4013 -122.030           2510   \n",
       "2532       1921             0    98117  47.6865 -122.379           1440   \n",
       "11381      1923             0    98103  47.6872 -122.346           1350   \n",
       "1703       1992             0    98092  47.2662 -122.088           1890   \n",
       "11649      2004             0    98029  47.5526 -121.994           2170   \n",
       "...         ...           ...      ...      ...      ...            ...   \n",
       "3253       1918             0    98122  47.6178 -122.299           1580   \n",
       "15432      1977             0    98006  47.5613 -122.128           2290   \n",
       "10924      1968             0    98032  47.3634 -122.279           2300   \n",
       "2871       1925             0    98022  47.2280 -122.088           1810   \n",
       "14516      1977             0    98042  47.3651 -122.094           1390   \n",
       "\n",
       "       sqft_lot15  \n",
       "9965        38487  \n",
       "2532         3840  \n",
       "11381        4000  \n",
       "1703       209959  \n",
       "11649        3720  \n",
       "...           ...  \n",
       "3253         2566  \n",
       "15432        9120  \n",
       "10924       11584  \n",
       "2871        94960  \n",
       "14516        5200  \n",
       "\n",
       "[3600 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15313</th>\n",
       "      <td>340000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2380</td>\n",
       "      <td>9362</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2380</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>98023</td>\n",
       "      <td>47.3148</td>\n",
       "      <td>-122.349</td>\n",
       "      <td>2190</td>\n",
       "      <td>9840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9628</th>\n",
       "      <td>920000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2880</td>\n",
       "      <td>5750</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1710</td>\n",
       "      <td>1170</td>\n",
       "      <td>1928</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>47.5874</td>\n",
       "      <td>-122.387</td>\n",
       "      <td>1640</td>\n",
       "      <td>5750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8427</th>\n",
       "      <td>420000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1320</td>\n",
       "      <td>4978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>940</td>\n",
       "      <td>380</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5266</td>\n",
       "      <td>-122.379</td>\n",
       "      <td>1260</td>\n",
       "      <td>4693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>1020000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2880</td>\n",
       "      <td>11340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1690</td>\n",
       "      <td>1190</td>\n",
       "      <td>1980</td>\n",
       "      <td>2013</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6113</td>\n",
       "      <td>-122.058</td>\n",
       "      <td>2530</td>\n",
       "      <td>11340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>690000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1710</td>\n",
       "      <td>17707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>530</td>\n",
       "      <td>1947</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5393</td>\n",
       "      <td>-122.216</td>\n",
       "      <td>2590</td>\n",
       "      <td>9508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7266</th>\n",
       "      <td>415000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1740</td>\n",
       "      <td>9046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1740</td>\n",
       "      <td>0</td>\n",
       "      <td>1956</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7402</td>\n",
       "      <td>-122.255</td>\n",
       "      <td>1830</td>\n",
       "      <td>9513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1520</td>\n",
       "      <td>2500</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1520</td>\n",
       "      <td>0</td>\n",
       "      <td>1912</td>\n",
       "      <td>0</td>\n",
       "      <td>98109</td>\n",
       "      <td>47.6347</td>\n",
       "      <td>-122.352</td>\n",
       "      <td>1880</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>395000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1953</td>\n",
       "      <td>0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6999</td>\n",
       "      <td>-122.364</td>\n",
       "      <td>1710</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>710000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>9732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5796</td>\n",
       "      <td>-122.229</td>\n",
       "      <td>1900</td>\n",
       "      <td>10200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17731</th>\n",
       "      <td>425000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1890</td>\n",
       "      <td>8400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1520</td>\n",
       "      <td>370</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98034</td>\n",
       "      <td>47.7103</td>\n",
       "      <td>-122.232</td>\n",
       "      <td>1830</td>\n",
       "      <td>7980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
       "15313   340000.0         4       2.50         2380      9362     2.0   \n",
       "9628    920000.0         4       2.75         2880      5750     1.5   \n",
       "8427    420000.0         4       1.75         1320      4978     1.0   \n",
       "2408   1020000.0         3       3.50         2880     11340     1.0   \n",
       "9729    690000.0         3       1.50         1710     17707     1.0   \n",
       "...          ...       ...        ...          ...       ...     ...   \n",
       "7266    415000.0         3       1.50         1740      9046     1.0   \n",
       "1065    550000.0         3       1.00         1520      2500     1.5   \n",
       "122     395000.0         2       1.00          770      6000     1.0   \n",
       "5199    710000.0         3       2.00         1780      9732     1.0   \n",
       "17731   425000.0         3       2.25         1890      8400     1.0   \n",
       "\n",
       "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
       "15313           0     0          3      8        2380              0   \n",
       "9628            0     0          5      9        1710           1170   \n",
       "8427            0     0          4      7         940            380   \n",
       "2408            0     0          3      8        1690           1190   \n",
       "9729            0     0          4      7        1180            530   \n",
       "...           ...   ...        ...    ...         ...            ...   \n",
       "7266            0     0          3      7        1740              0   \n",
       "1065            0     0          3      8        1520              0   \n",
       "122             0     0          3      6         770              0   \n",
       "5199            0     0          3      8        1780              0   \n",
       "17731           0     0          3      8        1520            370   \n",
       "\n",
       "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "15313      2000             0    98023  47.3148 -122.349           2190   \n",
       "9628       1928             0    98116  47.5874 -122.387           1640   \n",
       "8427       1942             0    98126  47.5266 -122.379           1260   \n",
       "2408       1980          2013    98074  47.6113 -122.058           2530   \n",
       "9729       1947             0    98040  47.5393 -122.216           2590   \n",
       "...         ...           ...      ...      ...      ...            ...   \n",
       "7266       1956             0    98028  47.7402 -122.255           1830   \n",
       "1065       1912             0    98109  47.6347 -122.352           1880   \n",
       "122        1953             0    98117  47.6999 -122.364           1710   \n",
       "5199       1967             0    98040  47.5796 -122.229           1900   \n",
       "17731      1977             0    98034  47.7103 -122.232           1830   \n",
       "\n",
       "       sqft_lot15  \n",
       "15313        9840  \n",
       "9628         5750  \n",
       "8427         4693  \n",
       "2408        11340  \n",
       "9729         9508  \n",
       "...           ...  \n",
       "7266         9513  \n",
       "1065         3600  \n",
       "122          6000  \n",
       "5199        10200  \n",
       "17731        7980  \n",
       "\n",
       "[3600 rows x 19 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task here is to complete the code in `featureNormalize` function:\n",
    "- Subtract the mean value of each feature from the dataset.\n",
    "- After subtracting the mean, additionally scale (divide) the feature values by their respective “standard deviations.”\n",
    "\n",
    "The standard deviation is a way of measuring how much variation there is in the range of values of a particular feature (most data points will lie within ±2 standard deviations of the mean); this is an alternative to taking the range of values (max-min). In `numpy`, you can use the `std` function to compute the standard deviation. \n",
    "\n",
    "For example, the quantity `X[:, 0]` contains all the values of $x_1$ (house sizes) in the training set, so `np.std(X[:, 0])` computes the standard deviation of the house sizes.\n",
    "At the time that the function `featureNormalize` is called, the extra column of 1’s corresponding to $x_0 = 1$ has not yet been added to $X$. \n",
    "\n",
    "You will do this for all the features and your code should work with datasets of all sizes (any number of features / examples). Note that each column of the matrix $X$ corresponds to one feature.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Implementation Note:** When normalizing the features, it is important\n",
    "to store the values used for normalization - the mean value and the standard deviation used for the computations. After learning the parameters\n",
    "from the model, we often want to predict the prices of houses we have not\n",
    "seen before. Given a new x value (living room area and number of bedrooms), we must first normalize x using the mean and standard deviation that we had previously computed from the training set.\n",
    "</div>\n",
    "<a id=\"featureNormalize\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  featureNormalize(X):\n",
    "    \"\"\"\n",
    "    Normalizes the features in X. returns a normalized version of X where\n",
    "    the mean value of each feature is 0 and the standard deviation\n",
    "    is 1. This is often a good preprocessing step to do when working with\n",
    "    learning algorithms.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_norm : array_like\n",
    "        The normalized dataset of shape (m x n).\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    First, for each feature dimension, compute the mean of the feature\n",
    "    and subtract it from the dataset, storing the mean value in mu. \n",
    "    Next, compute the  standard deviation of each feature and divide\n",
    "    each feature by it's standard deviation, storing the standard deviation \n",
    "    in sigma. \n",
    "    \n",
    "    Note that X is a matrix where each column is a feature and each row is\n",
    "    an example. You needto perform the normalization separately for each feature. \n",
    "    \n",
    "    Hint\n",
    "    ----\n",
    "    You might find the 'np.mean' and 'np.std' functions useful.\n",
    "    \"\"\"\n",
    "    # You need to set these values correctly\n",
    "    X_norm = X.copy()\n",
    "    mu = np.zeros(X.shape[1])\n",
    "    sigma = np.zeros(X.shape[1])\n",
    "\n",
    "    # =========================== YOUR CODE HERE =====================\n",
    "    mu = np.mean(X, axis = 0)\n",
    "    sigma = np.std(X, axis = 0)\n",
    "    X_norm = (X -mu) / sigma\n",
    "   \n",
    "    # ================================================================\n",
    "    return X_norm, mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the next cell to run the implemented `featureNormalize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>0.414821</td>\n",
       "      <td>-1.421992</td>\n",
       "      <td>-1.387553</td>\n",
       "      <td>-1.001300</td>\n",
       "      <td>-0.305569</td>\n",
       "      <td>-0.845001</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.672482</td>\n",
       "      <td>-0.514322</td>\n",
       "      <td>-0.760530</td>\n",
       "      <td>-0.667937</td>\n",
       "      <td>-1.558423</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>0.469931</td>\n",
       "      <td>0.679295</td>\n",
       "      <td>-0.856584</td>\n",
       "      <td>-0.262786</td>\n",
       "      <td>-0.292840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>-0.517569</td>\n",
       "      <td>-0.384138</td>\n",
       "      <td>0.560511</td>\n",
       "      <td>-0.080933</td>\n",
       "      <td>0.120818</td>\n",
       "      <td>0.137679</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>0.330675</td>\n",
       "      <td>-0.430354</td>\n",
       "      <td>0.611357</td>\n",
       "      <td>0.704454</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>-1.259223</td>\n",
       "      <td>-1.690858</td>\n",
       "      <td>2.300695</td>\n",
       "      <td>-0.469136</td>\n",
       "      <td>3.114751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11248</th>\n",
       "      <td>0.095145</td>\n",
       "      <td>0.653717</td>\n",
       "      <td>-0.413521</td>\n",
       "      <td>-0.470735</td>\n",
       "      <td>-0.260022</td>\n",
       "      <td>-0.845001</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.672482</td>\n",
       "      <td>-0.514322</td>\n",
       "      <td>-0.736073</td>\n",
       "      <td>0.368733</td>\n",
       "      <td>-0.732293</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>0.711641</td>\n",
       "      <td>0.046295</td>\n",
       "      <td>-1.225054</td>\n",
       "      <td>-0.498615</td>\n",
       "      <td>-0.290897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15516</th>\n",
       "      <td>0.492077</td>\n",
       "      <td>-1.421992</td>\n",
       "      <td>-1.387553</td>\n",
       "      <td>-0.546530</td>\n",
       "      <td>-0.279431</td>\n",
       "      <td>0.137679</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>0.942746</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>-0.514322</td>\n",
       "      <td>-0.246922</td>\n",
       "      <td>-0.667937</td>\n",
       "      <td>-0.911887</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>0.730234</td>\n",
       "      <td>1.004427</td>\n",
       "      <td>-1.239503</td>\n",
       "      <td>0.945834</td>\n",
       "      <td>-0.304497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14431</th>\n",
       "      <td>0.521380</td>\n",
       "      <td>-0.384138</td>\n",
       "      <td>-0.413521</td>\n",
       "      <td>0.200591</td>\n",
       "      <td>-0.110698</td>\n",
       "      <td>-0.845001</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>0.942746</td>\n",
       "      <td>-0.672482</td>\n",
       "      <td>0.330675</td>\n",
       "      <td>0.596863</td>\n",
       "      <td>-0.667937</td>\n",
       "      <td>-0.409025</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>-0.924548</td>\n",
       "      <td>1.445369</td>\n",
       "      <td>-0.386966</td>\n",
       "      <td>1.107967</td>\n",
       "      <td>-0.030741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  bedrooms  bathrooms  sqft_living  sqft_lot    floors  \\\n",
       "2581   0.414821 -1.421992  -1.387553    -1.001300 -0.305569 -0.845001   \n",
       "5391  -0.517569 -0.384138   0.560511    -0.080933  0.120818  0.137679   \n",
       "11248  0.095145  0.653717  -0.413521    -0.470735 -0.260022 -0.845001   \n",
       "15516  0.492077 -1.421992  -1.387553    -0.546530 -0.279431  0.137679   \n",
       "14431  0.521380 -0.384138  -0.413521     0.200591 -0.110698 -0.845001   \n",
       "\n",
       "       waterfront      view  condition     grade  sqft_above  sqft_basement  \\\n",
       "2581    -0.093707 -0.315375  -0.672482 -0.514322   -0.760530      -0.667937   \n",
       "5391    -0.093707 -0.315375   0.832935  0.330675   -0.430354       0.611357   \n",
       "11248   -0.093707 -0.315375  -0.672482 -0.514322   -0.736073       0.368733   \n",
       "15516   -0.093707  0.942746   0.832935 -0.514322   -0.246922      -0.667937   \n",
       "14431   -0.093707  0.942746  -0.672482  0.330675    0.596863      -0.667937   \n",
       "\n",
       "       yr_built  yr_renovated   zipcode       lat      long  sqft_living15  \\\n",
       "2581  -1.558423     -0.221023  0.469931  0.679295 -0.856584      -0.262786   \n",
       "5391   0.704454     -0.221023 -1.259223 -1.690858  2.300695      -0.469136   \n",
       "11248 -0.732293     -0.221023  0.711641  0.046295 -1.225054      -0.498615   \n",
       "15516 -0.911887     -0.221023  0.730234  1.004427 -1.239503       0.945834   \n",
       "14431 -0.409025     -0.221023 -0.924548  1.445369 -0.386966       1.107967   \n",
       "\n",
       "       sqft_lot15  \n",
       "2581    -0.292840  \n",
       "5391     3.114751  \n",
       "11248   -0.290897  \n",
       "15516   -0.304497  \n",
       "14431   -0.030741  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call featureNormalize on the loaded data\n",
    "X_norm_train, mu_train, sigma_train = featureNormalize(train)\n",
    "\n",
    "X_norm_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_test, mu_test, sigma_test = featureNormalize(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm_validate, mu_validate, sigma_validate = featureNormalize(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the `featureNormalize` function is tested, we now add the intercept term to `X_norm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.414821</td>\n",
       "      <td>-1.421992</td>\n",
       "      <td>-1.387553</td>\n",
       "      <td>-1.001300</td>\n",
       "      <td>-0.305569</td>\n",
       "      <td>-0.845001</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.672482</td>\n",
       "      <td>-0.514322</td>\n",
       "      <td>-0.760530</td>\n",
       "      <td>-0.667937</td>\n",
       "      <td>-1.558423</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>0.469931</td>\n",
       "      <td>0.679295</td>\n",
       "      <td>-0.856584</td>\n",
       "      <td>-0.262786</td>\n",
       "      <td>-0.292840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517569</td>\n",
       "      <td>-0.384138</td>\n",
       "      <td>0.560511</td>\n",
       "      <td>-0.080933</td>\n",
       "      <td>0.120818</td>\n",
       "      <td>0.137679</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>0.330675</td>\n",
       "      <td>-0.430354</td>\n",
       "      <td>0.611357</td>\n",
       "      <td>0.704454</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>-1.259223</td>\n",
       "      <td>-1.690858</td>\n",
       "      <td>2.300695</td>\n",
       "      <td>-0.469136</td>\n",
       "      <td>3.114751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095145</td>\n",
       "      <td>0.653717</td>\n",
       "      <td>-0.413521</td>\n",
       "      <td>-0.470735</td>\n",
       "      <td>-0.260022</td>\n",
       "      <td>-0.845001</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>-0.315375</td>\n",
       "      <td>-0.672482</td>\n",
       "      <td>-0.514322</td>\n",
       "      <td>-0.736073</td>\n",
       "      <td>0.368733</td>\n",
       "      <td>-0.732293</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>0.711641</td>\n",
       "      <td>0.046295</td>\n",
       "      <td>-1.225054</td>\n",
       "      <td>-0.498615</td>\n",
       "      <td>-0.290897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492077</td>\n",
       "      <td>-1.421992</td>\n",
       "      <td>-1.387553</td>\n",
       "      <td>-0.546530</td>\n",
       "      <td>-0.279431</td>\n",
       "      <td>0.137679</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>0.942746</td>\n",
       "      <td>0.832935</td>\n",
       "      <td>-0.514322</td>\n",
       "      <td>-0.246922</td>\n",
       "      <td>-0.667937</td>\n",
       "      <td>-0.911887</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>0.730234</td>\n",
       "      <td>1.004427</td>\n",
       "      <td>-1.239503</td>\n",
       "      <td>0.945834</td>\n",
       "      <td>-0.304497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521380</td>\n",
       "      <td>-0.384138</td>\n",
       "      <td>-0.413521</td>\n",
       "      <td>0.200591</td>\n",
       "      <td>-0.110698</td>\n",
       "      <td>-0.845001</td>\n",
       "      <td>-0.093707</td>\n",
       "      <td>0.942746</td>\n",
       "      <td>-0.672482</td>\n",
       "      <td>0.330675</td>\n",
       "      <td>0.596863</td>\n",
       "      <td>-0.667937</td>\n",
       "      <td>-0.409025</td>\n",
       "      <td>-0.221023</td>\n",
       "      <td>-0.924548</td>\n",
       "      <td>1.445369</td>\n",
       "      <td>-0.386966</td>\n",
       "      <td>1.107967</td>\n",
       "      <td>-0.030741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.414821 -1.421992 -1.387553 -1.001300 -0.305569 -0.845001 -0.093707   \n",
       "1  1.0 -0.517569 -0.384138  0.560511 -0.080933  0.120818  0.137679 -0.093707   \n",
       "2  1.0  0.095145  0.653717 -0.413521 -0.470735 -0.260022 -0.845001 -0.093707   \n",
       "3  1.0  0.492077 -1.421992 -1.387553 -0.546530 -0.279431  0.137679 -0.093707   \n",
       "4  1.0  0.521380 -0.384138 -0.413521  0.200591 -0.110698 -0.845001 -0.093707   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "0 -0.315375 -0.672482 -0.514322 -0.760530 -0.667937 -1.558423 -0.221023   \n",
       "1 -0.315375  0.832935  0.330675 -0.430354  0.611357  0.704454 -0.221023   \n",
       "2 -0.315375 -0.672482 -0.514322 -0.736073  0.368733 -0.732293 -0.221023   \n",
       "3  0.942746  0.832935 -0.514322 -0.246922 -0.667937 -0.911887 -0.221023   \n",
       "4  0.942746 -0.672482  0.330675  0.596863 -0.667937 -0.409025 -0.221023   \n",
       "\n",
       "         15        16        17        18        19  \n",
       "0  0.469931  0.679295 -0.856584 -0.262786 -0.292840  \n",
       "1 -1.259223 -1.690858  2.300695 -0.469136  3.114751  \n",
       "2  0.711641  0.046295 -1.225054 -0.498615 -0.290897  \n",
       "3  0.730234  1.004427 -1.239503  0.945834 -0.304497  \n",
       "4 -0.924548  1.445369 -0.386966  1.107967 -0.030741  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add intercept term to X\n",
    "Train = pd.DataFrame(np.concatenate([np.ones((train.shape[0], 1)), X_norm_train], axis=1))\n",
    "Validate = pd.DataFrame(np.concatenate([np.ones((validate.shape[0], 1)), X_norm_validate], axis=1))\n",
    "Test = pd.DataFrame(np.concatenate([np.ones((test.shape[0], 1)), X_norm_test], axis=1))\n",
    "Train.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "### 3.2 Gradient Descent\n",
    "\n",
    "Previously, you implemented gradient descent on a univariate regression problem. The only difference now is that there is one more feature in the matrix $X$. The hypothesis function and the batch gradient descent update\n",
    "rule remain unchanged. \n",
    "\n",
    "You should complete the code for the functions `computeCostMulti` and `gradientDescentMulti` to implement the cost function and gradient descent for linear regression with multiple variables. If your code in the previous part (single variable) already supports multiple variables, you can use it here too.\n",
    "Make sure your code supports any number of features and is well-vectorized.\n",
    "You can use the `shape` property of `numpy` arrays to find out how many features are present in the dataset.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Implementation Note:** In the multivariate case, the cost function can\n",
    "also be written in the following vectorized form:\n",
    "\n",
    "$$ J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y}) $$\n",
    "\n",
    "where \n",
    "\n",
    "$$ X = \\begin{pmatrix}\n",
    "          - (x^{(1)})^T - \\\\\n",
    "          - (x^{(2)})^T - \\\\\n",
    "          \\vdots \\\\\n",
    "          - (x^{(m)})^T - \\\\ \\\\\n",
    "        \\end{pmatrix} \\qquad \\mathbf{y} = \\begin{bmatrix} y^{(1)} \\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(m)} \\\\\\end{bmatrix}$$\n",
    "\n",
    "the vectorized version is efficient when you are working with numerical computing tools like `numpy`. If you are an expert with matrix operations, you can prove to yourself that the two forms are equivalent.\n",
    "</div>\n",
    "\n",
    "<a id=\"computeCostMulti\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMulti(X, y, theta):\n",
    "    \"\"\"\n",
    "    Compute cost for linear regression with multiple variables.\n",
    "    Computes the cost of using theta as the parameter for linear regression to fit the data points in X and y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        A vector of shape (m, ) for the values at a given data point.\n",
    "    \n",
    "    theta : array_like\n",
    "        The linear regression parameters. A vector of shape (n+1, )\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J : float\n",
    "        The value of the cost function. \n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Compute the cost of a particular choice of theta. You should set J to the cost.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "    \n",
    "    # You need to return the following variable correctly\n",
    "    J = 0\n",
    "    \n",
    "    # ======================= YOUR CODE HERE ===========================\n",
    "    \n",
    "    h = np.dot(X, theta)\n",
    "    J= (1/(2 * m)) * np.sum(np.square(np.dot(X, theta) - y))\n",
    "    \n",
    "    # ==================================================================\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentMulti(X, y, theta, alpha, num_iters):\n",
    "    \"\"\"\n",
    "    Performs gradient descent to learn theta.\n",
    "    Updates theta by taking num_iters gradient steps with learning rate alpha.\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array_like\n",
    "        The dataset of shape (m x n+1).\n",
    "    \n",
    "    y : array_like\n",
    "        A vector of shape (m, ) for the values at a given data point.\n",
    "    \n",
    "    theta : array_like\n",
    "        The linear regression parameters. A vector of shape (n+1, )\n",
    "    \n",
    "    alpha : float\n",
    "        The learning rate for gradient descent. \n",
    "    \n",
    "    num_iters : int\n",
    "        The number of iterations to run gradient descent. \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    theta : array_like\n",
    "        The learned linear regression parameters. A vector of shape (n+1, ).\n",
    "    \n",
    "    J_history : list\n",
    "        A python list for the values of the cost function after each iteration.\n",
    "    \n",
    "    Instructions\n",
    "    ------------\n",
    "    Peform a single gradient step on the parameter vector theta.\n",
    "\n",
    "    While debugging, it can be useful to print out the values of \n",
    "    the cost function (computeCost) and gradient here.\n",
    "    \"\"\"\n",
    "    # Initialize some useful values\n",
    "    m = y.shape[0] # number of training examples\n",
    "    \n",
    "    # make a copy of theta, which will be updated by gradient descent\n",
    "    theta = theta.copy()\n",
    "    \n",
    "    J_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # ======================= YOUR CODE HERE ==========================\n",
    "        \n",
    "        hypothesis=0\n",
    "        theta = theta - (alpha / m) * (np.dot(X, theta) - y).dot(X)\n",
    "        \n",
    "        # =================================================================\n",
    "        \n",
    "        # save the cost J in every iteration\n",
    "        J_history.append(computeCostMulti(X, y, theta))\n",
    "    \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1  Selecting learning rates\n",
    "\n",
    "In this part of the exercise, you will get to try out different learning rates for the dataset and find a learning rate that converges quickly. You can change the learning rate by modifying the following code and changing the part of the code that sets the learning rate.\n",
    "\n",
    "Use your implementation of `gradientDescentMulti` function and run gradient descent for about 50 iterations at the chosen learning rate. The function should also return the history of $J(\\theta)$ values in a vector $J$.\n",
    "\n",
    "After the last iteration, plot the J values against the number of the iterations.\n",
    "\n",
    "If you picked a learning rate within a good range, your plot look similar as the following Figure. \n",
    "\n",
    "![](Figures/learning_rate.png)\n",
    "\n",
    "If your graph looks very different, especially if your value of $J(\\theta)$ increases or even blows up, adjust your learning rate and try again. We recommend trying values of the learning rate $\\alpha$ on a log-scale, at multiplicative steps of about 3 times the previous value (i.e., 0.3, 0.1, 0.03, 0.01 and so on). You may also want to adjust the number of iterations you are running if that will help you see the overall trend in the curve.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**Implementation Note:** If your learning rate is too large, $J(\\theta)$ can diverge and ‘blow up’, resulting in values which are too large for computer calculations. In these situations, `numpy` will tend to return\n",
    "NaNs. NaN stands for ‘not a number’ and is often caused by undefined operations that involve −∞ and +∞.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**MATPLOTLIB tip:** To compare how different learning learning rates affect convergence, it is helpful to plot $J$ for several learning rates on the same figure. This can be done by making `alpha` a python list, and looping across the values within this list, and calling the plot function in every iteration of the loop. It is also useful to have a legend to distinguish the different lines within the plot. Search online for `pyplot.legend` for help on showing legends in `matplotlib`.\n",
    "</div>\n",
    "\n",
    "Notice the changes in the convergence curves as the learning rate changes. With a small learning rate, you should find that gradient descent takes a very long time to converge to the optimal value. Conversely, with a large learning rate, gradient descent might not converge or might even diverge!\n",
    "Using the best learning rate that you found, run the script\n",
    "to run gradient descent until convergence to find the final values of $\\theta$. Next,\n",
    "use this value of $\\theta$ to predict the price of a house with 1650 square feet and\n",
    "3 bedrooms. You will use value later to check your implementation of the normal equations. Don’t forget to normalize your features when you make this prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "0.14472841646341508\n",
      "0     5.633842e-13\n",
      "2    -7.737195e-02\n",
      "3     8.304991e-02\n",
      "4     2.156635e-01\n",
      "5     1.149178e-02\n",
      "6    -2.588432e-03\n",
      "7     1.609826e-01\n",
      "8     1.110005e-01\n",
      "9     5.005565e-02\n",
      "10    2.813038e-01\n",
      "11    2.072211e-01\n",
      "12    6.555514e-02\n",
      "13   -2.137072e-01\n",
      "14    2.116586e-02\n",
      "15   -8.751215e-02\n",
      "16    2.194327e-01\n",
      "17   -7.671679e-02\n",
      "18    6.368353e-02\n",
      "19   -2.952077e-02\n",
      "Name: 1, dtype: float64\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "############## TRAINING #################\n",
    "# Choose some alpha value - change this\n",
    "alpha = 0.1\n",
    "num_iters = 400\n",
    "y = Train.iloc[:,1]\n",
    "x = Train.drop(columns =[1])\n",
    "\n",
    "J_values = []\n",
    "theta_of_min = []\n",
    "# init theta and run gradient descent\n",
    "\n",
    "for i in range(2,20) :\n",
    "    \n",
    "    theta_i = np.zeros(i)\n",
    "    theta_cov, J_history = gradientDescentMulti(x.iloc[:,0:i], y, theta_i, alpha, num_iters)\n",
    "    J_values.append(J_history[num_iters-1])\n",
    "    theta_of_min.append(theta_cov)\n",
    "    \n",
    "    \n",
    "for m in range(0,18):\n",
    "    min = J_values[0]\n",
    "    if J_values[m] < min:\n",
    "        min = J_values[m]\n",
    "    \n",
    "\n",
    "print(len(J_values))\n",
    "print(min)\n",
    "l = J_values.index(min)\n",
    "print(theta_of_min[l])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46150463028791755, 0.3698351684742909, 0.26054002602462384, 0.26089848553258344, 0.2610209326822432, 0.2489256960292131, 0.23538190707922468, 0.23238108261083856, 0.21527869662614588, 0.2151667280745348, 0.21506522905543596, 0.18536205770422318, 0.18524579821537432, 0.18508121238216807, 0.16189255800019686, 0.16137612383503172, 0.15973205083290004, 0.15937606952955422]\n",
      "0.15937606952955422\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "################ VALIDATION ##################\n",
    "\n",
    "y_val = Validate.iloc[:,1]\n",
    "x_val = Validate.drop(columns =[1])\n",
    "J_vals = []\n",
    "\n",
    "for i in range(2,20) :\n",
    "    \n",
    "    J= computeCostMulti(x_val.iloc[:,0:i], y_val, theta_of_min[i-2])\n",
    "    J_vals.append(J)\n",
    "    \n",
    "for m in range(0,18):\n",
    "    min = J_vals[0]\n",
    "    if J_vals[m] < min:\n",
    "        min = J_vals[m]\n",
    "\n",
    "\n",
    "print(J_vals)\n",
    "print(min)\n",
    "l = J_vals.index(min)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15918091593687728\n"
     ]
    }
   ],
   "source": [
    "################ TESTING ##################\n",
    "\n",
    "y_test = Test.iloc[:,1]\n",
    "x_test = Test.drop(columns =[1])\n",
    "\n",
    "J_test= computeCostMulti(x_test, y_test, theta_of_min[17])\n",
    "\n",
    "print(J_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Degrees = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "J_values\n",
    "J_vals\n",
    "pyplot.xlabel('Degree')\n",
    "pyplot.ylabel('Cross Validation vs Training Error')\n",
    "\n",
    "pyplot.plot(Degrees, J_values)\n",
    "pyplot.plot(Degrees, J_vals )\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
